{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在某些情况下，multiprocessing 是 threading 的一个替代者，用于编写需要利用多个 CPU 来规避由于 Python 的全局解释器锁带来的计算瓶颈问题的场合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE: <Process(Process-1, initial)> False\n",
      "DURING: <Process(Process-1, started)> True\n",
      "TERMINATED: <Process(Process-1, started)> True\n",
      "JOINED: <Process(Process-1, stopped[SIGTERM])> False\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "\n",
    "def slow_worker():\n",
    "    print('Starting worker')\n",
    "    time.sleep(0.1)\n",
    "    print('Finished worker')\n",
    "\n",
    "\n",
    "\n",
    "p = multiprocessing.Process(target=slow_worker)\n",
    "print('BEFORE:', p, p.is_alive())\n",
    "\n",
    "p.start()\n",
    "print('DURING:', p, p.is_alive())\n",
    "\n",
    "p.terminate()  # 终止进程，及其子进程\n",
    "print('TERMINATED:', p, p.is_alive())\n",
    "\n",
    "p.join()\n",
    "print('JOINED:', p, p.is_alive())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting process for  exit_error\n",
      "Starting process for  exit_ok\n",
      "Starting process for  return_value\n",
      "Starting process for  raises\n",
      "Starting process for  terminated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process raises:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-5-a4b3dc014785>\", line 13, in raises\n",
      "    raise RuntimeError('There was an error')\n",
      "RuntimeError: There was an error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     exit_error exitcode=1\n",
      "        exit_ok exitcode=0\n",
      "   return_value exitcode=0\n",
      "         raises exitcode=1\n",
      "     terminated exitcode=-15\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "def exit_error():\n",
    "    sys.exit(1)\n",
    "    \n",
    "def exit_ok():\n",
    "    return \n",
    "\n",
    "def return_value():\n",
    "    return 1\n",
    "\n",
    "def raises():\n",
    "    raise RuntimeError('There was an error')\n",
    "    \n",
    "def terminated():\n",
    "    time.sleep(3)\n",
    "    \n",
    "jobs = []\n",
    "funcs = [exit_error, exit_ok, return_value, raises, terminated]\n",
    "for f in funcs:\n",
    "    print('Starting process for ', f.__name__)\n",
    "    j = multiprocessing.Process(target=f, name=f.__name__)\n",
    "    jobs.append(j)\n",
    "    j.start()\n",
    "    \n",
    "jobs[-1].terminate()\n",
    "for j in jobs:\n",
    "    j.join()\n",
    "    print(f\"{j.name:>15} exitcode={j.exitcode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO/Process-19] child process calling self.run()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing some work\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO/Process-19] process shutting down\n",
      "[DEBUG/Process-19] running all \"atexit\" finalizers with priority >= 0\n",
      "[DEBUG/Process-19] running the remaining \"atexit\" finalizers\n",
      "[INFO/Process-19] process exiting with exitcode 0\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "def worker():\n",
    "    print('doing some work')\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "multiprocessing.log_to_stderr(logging.DEBUG)\n",
    "p = multiprocessing.Process(target=worker)\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passing Messages to Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing sth for sdjaklsdj in Process-3\n",
      "Doing sth for gahahah in Process-4\n"
     ]
    }
   ],
   "source": [
    "class MyFancyClass:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "    def  do_sth(self):\n",
    "        proc_name = multiprocessing.current_process().name\n",
    "        print(f\"Doing sth for {self.name} in {proc_name}\")\n",
    "        \n",
    "def worker(q):\n",
    "    obj = q.get()\n",
    "    obj.do_sth()\n",
    "    \n",
    "\n",
    "queue = multiprocessing.Queue()\n",
    "p1 = multiprocessing.Process(target=worker, args=(queue,))\n",
    "p2 = multiprocessing.Process(target=worker, args=(queue,))\n",
    "p1.start()\n",
    "p2.start()\n",
    "queue.put(MyFancyClass('sdjaklsdj'))\n",
    "queue.put(MyFancyClass('gahahah'))\n",
    "# wait for worker to finish\n",
    "queue.close()\n",
    "queue.join_thread()\n",
    "p1.join()\n",
    "p2.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create 8 consumers\n",
      "Consumer-9:4 * 4\n",
      "Consumer-5:0 * 0\n",
      "Consumer-8:3 * 3\n",
      "Consumer-7:2 * 2\n",
      "Consumer-6:1 * 1\n",
      "Consumer-10:5 * 5\n",
      "Consumer-11:6 * 6\n",
      "Consumer-12:7 * 7\n",
      "Consumer-5:8 * 8\n",
      "Consumer-9:9 * 9\n",
      "Consumer-7 Exiting\n",
      "Consumer-6 Exiting\n",
      "Consumer-10 Exiting\n",
      "Consumer-8 Exiting\n",
      "Consumer-11 Exiting\n",
      "Consumer-12 Exiting\n",
      "Consumer-5 Exiting\n",
      "Consumer-9 Exiting\n",
      "Result: 0 * 0 = 0\n",
      "Result: 4 * 4 = 16\n",
      "Result: 2 * 2 = 4\n",
      "Result: 1 * 1 = 1\n",
      "Result: 5 * 5 = 25\n",
      "Result: 3 * 3 = 9\n",
      "Result: 6 * 6 = 36\n",
      "Result: 7 * 7 = 49\n",
      "Result: 8 * 8 = 64\n",
      "Result: 9 * 9 = 81\n"
     ]
    }
   ],
   "source": [
    "class Consumer(multiprocessing.Process):\n",
    "    def __init__(self, task_queue, result_queue):\n",
    "        super().__init__()\n",
    "        self.task_queue = task_queue\n",
    "        self.result_queue = result_queue\n",
    "        \n",
    "    def run(self):\n",
    "        proc_name = self.name\n",
    "        while True:\n",
    "            next_task = self.task_queue.get()\n",
    "            if next_task is None:\n",
    "                # Poison pill means shutdown\n",
    "                print(f\"{proc_name} Exiting\")\n",
    "                self.task_queue.task_done()\n",
    "                break\n",
    "            print(f\"{proc_name}:{next_task}\")\n",
    "            answer = next_task()\n",
    "            self.task_queue.task_done()\n",
    "            self.result_queue.put(answer)\n",
    "            \n",
    "class Task:\n",
    "    def __init__(self, a, b):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "    def __call__(self):\n",
    "        time.sleep(0.1) # pretend to take time to do the work\n",
    "        return f\"{self.a} * {self.b} = {self.a*self.b}\"\n",
    "    def __str__(self):\n",
    "        return f\"{self.a} * {self.b}\"\n",
    "\n",
    "# Establish communication queues\n",
    "tasks = multiprocessing.JoinableQueue()\n",
    "results = multiprocessing.Queue()\n",
    "\n",
    "# Start consumers\n",
    "num_consumers = multiprocessing.cpu_count()*2\n",
    "print(f\"create {num_consumers} consumers\")\n",
    "\n",
    "consumers = [Consumer(tasks, results) for _ in range(num_consumers)]\n",
    "for w in consumers:\n",
    "    w.start()\n",
    "    \n",
    "num_jobs = 10\n",
    "for i in range(num_jobs):\n",
    "    tasks.put(Task(i, i))\n",
    "    \n",
    "# add a posion pill for each consumer\n",
    "for i in range(num_consumers):\n",
    "    tasks.put(None)\n",
    "\n",
    "# wait for all task to finish\n",
    "tasks.join()\n",
    "while num_jobs:\n",
    "    result = results.get()\n",
    "    print(\"Result:\", result)\n",
    "    num_jobs -=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signaling between Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait for event starting:\n",
      "wait for event timeout starting:\n",
      "wait for call e is set:\n",
      "wait_for_event_timeout, e.is_set() --> False\n",
      "main event is set\n",
      "wait_for_event, e.is_set() --> True\n"
     ]
    }
   ],
   "source": [
    "def wait_for_event(e):\n",
    "    print('wait for event starting:')\n",
    "    e.wait()\n",
    "    print('wait_for_event, e.is_set() -->', e.is_set())\n",
    "\n",
    "def wait_for_event_timeout(e, t):\n",
    "    print('wait for event timeout starting:')\n",
    "    e.wait(t)\n",
    "    print('wait_for_event_timeout, e.is_set() -->', e.is_set())\n",
    "    \n",
    "e = multiprocessing.Event()\n",
    "w1 = multiprocessing.Process(target=wait_for_event, args=(e,), name='block')\n",
    "w1.start()\n",
    "w2 = multiprocessing.Process(target=wait_for_event_timeout, args=(e,2), name='non-block')\n",
    "w2.start()\n",
    "print('wait for call e is set:')\n",
    "time.sleep(4)\n",
    "e.set()\n",
    "print('main event is set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controlling Access to Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lock acquied via with \n",
      "lock acquied via directly \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "def work_with(lock, stream):\n",
    "    with lock:\n",
    "        stream.write('lock acquied via with \\n')\n",
    "        \n",
    "def work_not_with(lock, stream):\n",
    "    lock.acquire()\n",
    "    try:\n",
    "        stream.write('lock acquied via directly \\n')      \n",
    "    finally:\n",
    "        lock.release()\n",
    "        \n",
    "lock = multiprocessing.Lock()\n",
    "w = multiprocessing.Process(target=work_with, args=(lock, sys.stdout))\n",
    "nw = multiprocessing.Process(target=work_not_with, args=(lock, sys.stdout))\n",
    "w.start()\n",
    "nw.start()\n",
    "w.join()\n",
    "nw.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synchronizing Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting  stage2[1]\n",
      "Starting  stage2[2]\n",
      "Starting  s1\n",
      "s1 done and ready for stage_2\n",
      "stage2[2] running\n",
      "stage2[1] running\n"
     ]
    }
   ],
   "source": [
    "def stage_1(cond):\n",
    "    name = multiprocessing.current_process().name\n",
    "    print('Starting ', name)\n",
    "    with cond:\n",
    "        print(f'{name} done and ready for stage_2')\n",
    "        cond.notify_all()\n",
    "        \n",
    "def stage_2(cond):\n",
    "    name = multiprocessing.current_process().name\n",
    "    print('Starting ', name)\n",
    "    with cond:\n",
    "        cond.wait()\n",
    "        print(f'{name} running')\n",
    "        \n",
    "condition = multiprocessing.Condition()\n",
    "s1 = multiprocessing.Process(target=stage_1, args=(condition, ), name = 's1')\n",
    "s2_clients = [multiprocessing.Process(target=stage_2, args=(condition, ), name = f'stage2[{i}]') for i in range(1,3)]\n",
    "for c in s2_clients:\n",
    "    c.start()\n",
    "    time.sleep(1)\n",
    "s1.start()\n",
    "s1.join()\n",
    "for c in s2_clients:\n",
    "    c.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controlling Concurrent Access to Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activating worker[0] now running ['worker[0]', 'worker[1]']\n",
      "Activating worker[1] now running ['worker[0]', 'worker[1]', 'worker[2]']\n",
      "Activating worker[2] now running ['worker[0]', 'worker[1]', 'worker[2]']\n",
      "now running  ['worker[0]', 'worker[1]', 'worker[2]']\n",
      "now running  ['worker[0]', 'worker[1]', 'worker[2]']\n",
      "Activating worker[3] now running ['worker[0]', 'worker[2]', 'worker[3]']\n",
      "now running  ['worker[0]', 'worker[1]', 'worker[2]']\n",
      "now running  ['worker[0]', 'worker[1]', 'worker[2]']\n",
      "Activating worker[4] now running ['worker[0]', 'worker[2]', 'worker[4]']\n",
      "now running  ['worker[0]', 'worker[2]', 'worker[3]']\n",
      "now running  ['worker[0]', 'worker[2]']\n",
      "Activating worker[5] now running ['worker[0]', 'worker[2]', 'worker[5]']\n",
      "Activating worker[6] now running ['worker[2]', 'worker[5]', 'worker[6]']\n",
      "now running  ['worker[0]', 'worker[2]', 'worker[4]']\n",
      "now running  ['worker[0]', 'worker[2]', 'worker[4]']\n",
      "Activating worker[7] now running ['worker[5]', 'worker[6]', 'worker[7]']\n",
      "Activating worker[8] now running ['worker[6]', 'worker[7]', 'worker[8]']\n",
      "now running  ['worker[5]', 'worker[6]', 'worker[7]']\n",
      "now running  ['worker[5]', 'worker[6]', 'worker[7]']\n",
      "now running  ['worker[6]', 'worker[7]', 'worker[8]']\n",
      "now running  ['worker[6]', 'worker[7]', 'worker[8]']\n",
      "now running  ['worker[6]', 'worker[7]', 'worker[8]']\n",
      "now running  ['worker[6]', 'worker[7]', 'worker[8]']\n",
      "now running  ['worker[6]', 'worker[7]', 'worker[8]']\n",
      "Activating worker[9] now running ['worker[6]', 'worker[8]', 'worker[9]']\n",
      "now running  ['worker[6]', 'worker[7]', 'worker[8]']\n",
      "now running  ['worker[6]', 'worker[7]', 'worker[8]']\n",
      "now running  ['worker[6]', 'worker[8]']\n",
      "now running  ['worker[8]']\n",
      "now running  []\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "class ActivePool:\n",
    "    def __init__(self):\n",
    "        self.mgr = multiprocessing.Manager()\n",
    "        self.active = self.mgr.list()\n",
    "        self.lock = multiprocessing.Lock()\n",
    "    def make_active(self, name):\n",
    "        with self.lock:\n",
    "            self.active.append(name)\n",
    "    def make_inactive(self, name):\n",
    "        with self.lock:\n",
    "            self.active.remove(name)\n",
    "    def __str__(self):\n",
    "        with self.lock:\n",
    "            return str(self.active)\n",
    "            \n",
    "def worker(s, pool):\n",
    "    name = multiprocessing.current_process().name\n",
    "    with s:\n",
    "        pool.make_active(name)\n",
    "        print(f\"Activating {name} now running {pool}\")\n",
    "        time.sleep(random.random())\n",
    "        pool.make_inactive(name)\n",
    "        \n",
    "pool = ActivePool()\n",
    "s = multiprocessing.Semaphore(3)\n",
    "jobs = [multiprocessing.Process(target=worker, args=(s, pool), name = f'worker[{i}]') for i in range(10)]\n",
    "for j in jobs:\n",
    "    j.start()\n",
    "    \n",
    "while True:\n",
    "    alive = 0\n",
    "    for j in jobs:\n",
    "        if j.is_alive():\n",
    "            alive += 1\n",
    "            j.join(timeout=0.1)\n",
    "            print('now running ', pool)\n",
    "    if alive == 0:\n",
    "        print('Done')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing Shared State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0),\n",
      " (2, 4),\n",
      " (1, 2),\n",
      " (3, 6),\n",
      " (4, 8),\n",
      " (5, 10),\n",
      " (6, 12),\n",
      " (7, 14),\n",
      " (9, 18),\n",
      " (8, 16)]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "def worker(d, key, value):\n",
    "    d[key] = value\n",
    "    \n",
    "mgr = multiprocessing.Manager()\n",
    "d = mgr.dict()\n",
    "jobs = [multiprocessing.Process(target=worker, args=(d, i, i*2)) for i in range(10)]\n",
    "for j in jobs:\n",
    "    j.start()\n",
    "for j in jobs:\n",
    "    j.join()\n",
    "pprint.pprint(d.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared Namespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before event, error: 'Namespace' object has no attribute 'value'\n",
      "After event: This is the value\n"
     ]
    }
   ],
   "source": [
    "def producer(ns, event):\n",
    "    ns.value = 'This is the value'\n",
    "    event.set()\n",
    "\n",
    "\n",
    "def consumer(ns, event):\n",
    "    try:\n",
    "        print('Before event: {}'.format(ns.value))\n",
    "    except Exception as err:\n",
    "        print('Before event, error:', str(err))\n",
    "    event.wait()\n",
    "    print('After event:', ns.value)\n",
    "\n",
    "\n",
    "mgr = multiprocessing.Manager()\n",
    "namespace = mgr.Namespace()\n",
    "event = multiprocessing.Event()\n",
    "p = multiprocessing.Process(target=producer,args=(namespace, event),)\n",
    "c = multiprocessing.Process(target=consumer,args=(namespace, event),)\n",
    "\n",
    "c.start()\n",
    "p.start()\n",
    "\n",
    "c.join()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before event: []\n",
      "After event : []\n"
     ]
    }
   ],
   "source": [
    "def producer(ns, event):\n",
    "    # DOES NOT UPDATE GLOBAL VALUE!\n",
    "    ns.my_list.append('This is the value')\n",
    "    event.set()\n",
    "\n",
    "\n",
    "def consumer(ns, event):\n",
    "    print('Before event:', ns.my_list)\n",
    "    event.wait()\n",
    "    print('After event :', ns.my_list)\n",
    "\n",
    "\n",
    "\n",
    "mgr = multiprocessing.Manager()\n",
    "namespace = mgr.Namespace()\n",
    "namespace.my_list = []\n",
    "\n",
    "event = multiprocessing.Event()\n",
    "p = multiprocessing.Process(target=producer,args=(namespace, event),)\n",
    "c = multiprocessing.Process(target=consumer,args=(namespace, event),)\n",
    "\n",
    "c.start()\n",
    "p.start()\n",
    "\n",
    "c.join()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Namespace 中的可变数据类型并不会自动做相应的变化\n",
    "\n",
    "## Process Pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Buildin output <map object at 0x11129c358>\n",
      "Starting  ForkPoolWorker-2\n",
      "Starting  ForkPoolWorker-3\n",
      "Starting  ForkPoolWorker-4\n",
      "Starting  ForkPoolWorker-5\n",
      "Starting  ForkPoolWorker-6\n",
      "Starting  ForkPoolWorker-7\n",
      "Starting  ForkPoolWorker-8\n",
      "Starting  ForkPoolWorker-9\n",
      "Pool [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n"
     ]
    }
   ],
   "source": [
    "def do_cal(data):\n",
    "    return data*2\n",
    "\n",
    "def start_pro():\n",
    "    print('Starting ', multiprocessing.current_process().name)\n",
    "    \n",
    "inputs = list(range(10))\n",
    "print('Input:', inputs)\n",
    "bulidin_output = map(do_cal, inputs)\n",
    "print('Buildin output', bulidin_output)\n",
    "\n",
    "pool_size = multiprocessing.cpu_count()*2\n",
    "pool = multiprocessing.Pool(processes=pool_size, initializer=start_pro, maxtasksperchild=2,)\n",
    "pool_outputs = pool.map(do_cal, inputs)\n",
    "pool.close()\n",
    "pool.join()\n",
    "print('Pool', pool_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing MapReduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import itertools\n",
    "import string\n",
    "\n",
    "class SimpleMapReduce:\n",
    "    def __init__(self, map_func, reduce_func, num_workers=None):\n",
    "        self.map_func = map_func\n",
    "        self.reduce_func = reduce_func\n",
    "        self.pool = multiprocessing.Pool(num_workers)\n",
    "    def partition(self, mapped_values):\n",
    "        partitioned_data = collections.defaultdict(list)\n",
    "        for k, v in mapped_values:\n",
    "            partitioned_data[k].append(v)\n",
    "        return partitioned_data.items()\n",
    "    \n",
    "    def __call__(self, inputs, chunksize=1):\n",
    "        map_response = self.pool.map(self.map_func, inputs, chunksize=chunksize)\n",
    "        partitioned_data = self.partition(itertools.chain(*map_response))\n",
    "        reduced_values = self.pool.map(self.reduce_func, partitioned_data)\n",
    "        return reduced_values\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_words(filename):\n",
    "    STOP_WORDS = set([\n",
    "        'a', 'an', 'and', 'are', 'as', 'be', 'by', 'for', 'if','in', 'is', 'it', 'of', 'or', 'py', 'rst', 'that', 'the','to', 'with',\n",
    "    ])\n",
    "    TR = str.maketrans({p : ' ' for p in string.punctuation})\n",
    "    print(f\"{multiprocessing.current_process().name} reading {filename}\")\n",
    "    output = []\n",
    "    with open(filename, 'rt') as f:\n",
    "        for line in f:\n",
    "            if line.lstrip().startswith('..'):\n",
    "                continue\n",
    "            line = line.translate(TR)\n",
    "            for word in line.split():\n",
    "                word = word.lower()\n",
    "                if word.isalpha() and word not in STOP_WORDS:\n",
    "                    output.append((word, 1))\n",
    "    return output\n",
    "\n",
    "def count_words(item):\n",
    "    word, ouucrences = item\n",
    "    return (word, sum(ouucrences))\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ForkPoolWorker-18 reading subprocess_signal_parent_shell.py\n",
      "ForkPoolWorker-20 reading subprocess_signal_setgrp.py\n",
      "ForkPoolWorker-19 reading signal_parent.py\n",
      "ForkPoolWorker-21 reading repeater.py\n",
      "ForkPoolWorker-19 reading signal_child.py\n",
      "TOP 20 WORD\n",
      "[('signal', 24),\n",
      " ('import', 22),\n",
      " ('sys', 21),\n",
      " ('flush', 14),\n",
      " ('script', 14),\n",
      " ('child', 13),\n",
      " ('pid', 13),\n",
      " ('stdout', 10),\n",
      " ('print', 10),\n",
      " ('proc', 10),\n",
      " ('time', 10),\n",
      " ('os', 10),\n",
      " ('shell', 9),\n",
      " ('f', 8),\n",
      " ('file', 8),\n",
      " ('parent', 7),\n",
      " ('subprocess', 7),\n",
      " ('received', 6),\n",
      " ('sleep', 6),\n",
      " ('popen', 6)]\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "import glob\n",
    "import pprint\n",
    "\n",
    "inputs = glob.glob('*.py')\n",
    "mapper = SimpleMapReduce(file_to_words, count_words)\n",
    "word_counts = mapper(inputs)\n",
    "word_counts.sort(key=operator.itemgetter(1))\n",
    "word_counts.reverse()\n",
    "\n",
    "print('TOP 20 WORD')\n",
    "top20 = word_counts[:20]\n",
    "pprint.pprint(top20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

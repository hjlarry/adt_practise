{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "codecs 模块提供了流和文件接口用于转换数据。它通常用于处理 Unicode 文本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import binascii\n",
    "\n",
    "def to_hex(t, nbytes):\n",
    "    \"\"\"Format text t as a sequence of nbyte long values separated by spaces\"\"\"\n",
    "    chars_per_item = nbytes*2\n",
    "    hex_version = binascii.hexlify(t)\n",
    "    return b' '.join(hex_version[start:start + chars_per_item] for start in range(0, len(hex_version), chars_per_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'61 62 63 64 65 66'\n",
      "b'6162 6364 6566'\n"
     ]
    }
   ],
   "source": [
    "print(to_hex(b'abcdef', 1))\n",
    "print(to_hex(b'abcdef', 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw: 'françaiS'\n",
      "  'f':LATIN SMALL LETTER F\n",
      "  'r':LATIN SMALL LETTER R\n",
      "  'a':LATIN SMALL LETTER A\n",
      "  'n':LATIN SMALL LETTER N\n",
      "  'ç':LATIN SMALL LETTER C WITH CEDILLA\n",
      "  'a':LATIN SMALL LETTER A\n",
      "  'i':LATIN SMALL LETTER I\n",
      "  'S':LATIN CAPITAL LETTER S\n",
      "UTF-8 : b'66 72 61 6e c3 a7 61 69 53'\n",
      "UTF-16 : b'ff fe 66 00 72 00 61 00 6e 00 e7 00 61 00 69 00 53 00'\n",
      "UTF-16 : b'fffe 6600 7200 6100 6e00 e700 6100 6900 5300'\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "text = 'françaiS'\n",
    "print(f'Raw: {text!r}')\n",
    "for c in text:\n",
    "    print(f\"  {c!r}:{unicodedata.name(c,c)}\")\n",
    "    \n",
    "print(f\"UTF-8 : {to_hex(text.encode('utf-8'),1)}\")\n",
    "print(f\"UTF-16 : {to_hex(text.encode('utf-16'),1)}\")\n",
    "print(f\"UTF-16 : {to_hex(text.encode('utf-16'),2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "def main(encoding):\n",
    "    filename = encoding + '.txt'\n",
    "    print('Writing to ', filename)\n",
    "    with codecs.open(filename, mode='w', encoding=encoding) as f:\n",
    "        f.write('françaiS')\n",
    "        \n",
    "    nbytes = {'utf-8': 1, 'utf-16':2, 'utf-32':3}.get(encoding, 1)\n",
    "    print('File Contents:')\n",
    "    with open(filename, mode='rb') as f:\n",
    "        print(to_hex(f.read(), nbytes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to  utf-8.txt\n",
      "File Contents:\n",
      "b'66 72 61 6e c3 a7 61 69 53'\n"
     ]
    }
   ],
   "source": [
    "main('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to  utf-16.txt\n",
      "File Contents:\n",
      "b'fffe 6600 7200 6100 6e00 e700 6100 6900 5300'\n"
     ]
    }
   ],
   "source": [
    "main('utf-16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to  utf-32.txt\n",
      "File Contents:\n",
      "b'fffe00 006600 000072 000000 610000 006e00 0000e7 000000 610000 006900 000053 000000'\n"
     ]
    }
   ],
   "source": [
    "main('utf-32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "françaiS\n"
     ]
    }
   ],
   "source": [
    "with codecs.open('utf-32.txt', mode='r', encoding='utf-32') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 字节顺序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOM          : b'fffe'\n",
      "BOM_BE       : b'feff'\n",
      "BOM_LE       : b'fffe'\n",
      "BOM_UTF8     : b'efbb bf'\n",
      "BOM_UTF16    : b'fffe'\n",
      "BOM_UTF16_BE : b'feff'\n",
      "BOM_UTF16_LE : b'fffe'\n",
      "BOM_UTF32    : b'fffe 0000'\n",
      "BOM_UTF32_BE : b'0000 feff'\n",
      "BOM_UTF32_LE : b'fffe 0000'\n"
     ]
    }
   ],
   "source": [
    "BOM_TYPES = [\n",
    "    'BOM', 'BOM_BE', 'BOM_LE',\n",
    "    'BOM_UTF8',\n",
    "    'BOM_UTF16', 'BOM_UTF16_BE', 'BOM_UTF16_LE',\n",
    "    'BOM_UTF32', 'BOM_UTF32_BE', 'BOM_UTF32_LE',\n",
    "]\n",
    "\n",
    "for name in BOM_TYPES:\n",
    "    print(f\"{name:12} : {to_hex(getattr(codecs, name), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Native order  : b'fffe'\n",
      "Selected order: b'feff'\n",
      "utf_16_be     : b'0066 0072 0061 006e 00e7 0061 0069 0073'\n"
     ]
    }
   ],
   "source": [
    "# 选择 UTF-16 编码的非本地编码\n",
    "if codecs.BOM_UTF16 == codecs.BOM_UTF16_BE:\n",
    "    bom = codecs.BOM_UTF16_LE\n",
    "    encoding = 'utf_16_le'\n",
    "else:\n",
    "    bom = codecs.BOM_UTF16_BE\n",
    "    encoding = 'utf_16_be'\n",
    "\n",
    "print('Native order  :', to_hex(codecs.BOM_UTF16, 2))\n",
    "print('Selected order:', to_hex(bom, 2))\n",
    "\n",
    "# 编码数据\n",
    "encoded_text = 'français'.encode(encoding)\n",
    "print('{:14}: {}'.format(encoding, to_hex(encoded_text, 2)))\n",
    "\n",
    "with open('nonnative-encoded.txt', mode='wb') as f:\n",
    "    # 写入字节顺序标记，它没有包含在编码文本中，因为选择编码的时候字节顺序被给定了。\n",
    "    f.write(bom)\n",
    "    # 写入编码文本的字节字符串\n",
    "    f.write(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw    : b'feff 0066 0072 0061 006e 00e7 0061 0069 0073'\n",
      "Decoded: 'français'\n"
     ]
    }
   ],
   "source": [
    "# 查看原生数据\n",
    "with open('nonnative-encoded.txt', mode='rb') as f:\n",
    "    raw_bytes = f.read()\n",
    "\n",
    "print('Raw    :', to_hex(raw_bytes, 2))\n",
    "\n",
    "# 重新打开文件，并且让 codecs 检测 BOM\n",
    "with codecs.open('nonnative-encoded.txt',\n",
    "                 mode='r',\n",
    "                 encoding='utf-16',\n",
    "                 ) as f:\n",
    "    decoded_text = f.read()\n",
    "\n",
    "print('Decoded:', repr(decoded_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 错误处理\n",
    "|错误模式\t|描述|\n",
    "| ------ | ------ |\n",
    "|strict\t|数据没有被正确转换将会引发错误。|\n",
    "|replace\t|对于不能编码的数据替换一个特殊的标记字符。|\n",
    "|ignore\t|跳过数据。|\n",
    "|xmlcharrefreplace\t|XML 字符 (仅用于编码)|\n",
    "|backslashreplace\t|转移序列 (仅用于编码)|\n",
    "\n",
    "### 编码错误"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(error_handling):\n",
    "    text = 'français'\n",
    "    try:\n",
    "        with codecs.open('encode_error.txt', 'w', encoding='ascii', errors=error_handling) as f:\n",
    "            f.write(text)\n",
    "    except UnicodeEncodeError as err:\n",
    "        print('ERROR:', err)\n",
    "    else:\n",
    "        with open('encode_error.txt', 'rb') as f:\n",
    "            print(f'file contents: {f.read()!r}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: 'ascii' codec can't encode character '\\xe7' in position 4: ordinal not in range(128)\n"
     ]
    }
   ],
   "source": [
    "main('strict')  # default value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file contents: b'fran?ais'\n"
     ]
    }
   ],
   "source": [
    "main('replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file contents: b'franais'\n"
     ]
    }
   ],
   "source": [
    "main('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file contents: b'fran&#231;ais'\n"
     ]
    }
   ],
   "source": [
    "main('xmlcharrefreplace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file contents: b'fran\\\\xe7ais'\n"
     ]
    }
   ],
   "source": [
    "main('backslashreplace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解码错误"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(error_handling):\n",
    "    text = 'français'\n",
    "    with codecs.open('decode_error.txt', 'w', encoding='utf-16') as f:\n",
    "        f.write(text)\n",
    "    \n",
    "    # 转化文件中的字节\n",
    "    with open('decode_error.txt', 'rb') as f:\n",
    "        print('File contents:', to_hex(f.read(),1))\n",
    "        \n",
    "    with codecs.open('decode_error.txt', 'r', encoding='utf-8', errors=error_handling) as f:\n",
    "        try:\n",
    "            data = f.read()\n",
    "        except UnicodeEncodeError as err:\n",
    "            print('ERROR:', err)\n",
    "        else:\n",
    "            print('Read   :', repr(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File contents: b'ff fe 66 00 72 00 61 00 6e 00 e7 00 61 00 69 00 73 00'\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-87fe0d190bef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'strict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-1d147407e954>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(error_handling)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'decode_error.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_handling\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeEncodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ERROR:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size, chars, firstline)\u001b[0m\n\u001b[1;32m    501\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m                 \u001b[0mnewchars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecodedbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeDecodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfirstline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "main('strict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File contents: b'ff fe 66 00 72 00 61 00 6e 00 e7 00 61 00 69 00 73 00'\n",
      "Read   : 'f\\x00r\\x00a\\x00n\\x00\\x00a\\x00i\\x00s\\x00'\n"
     ]
    }
   ],
   "source": [
    "main('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File contents: b'ff fe 66 00 72 00 61 00 6e 00 e7 00 61 00 69 00 73 00'\n",
      "Read   : '��f\\x00r\\x00a\\x00n\\x00�\\x00a\\x00i\\x00s\\x00'\n"
     ]
    }
   ],
   "source": [
    "main('replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编码转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starts as utf8: b'66 72 61 6e c3 a7 61 69 73'\n",
      "Encoded to UTF-16: b'fffe 6600 7200 6100 6e00 e700 6100 6900 7300'\n",
      "Back to UTF-8    : b'66 72 61 6e c3 a7 61 69 73'\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "\n",
    "data = 'français'\n",
    "utf8 = data.encode('utf-8')\n",
    "print('starts as utf8:', to_hex(utf8, 1))\n",
    "\n",
    "# 设置输出缓冲池，将它包装为EncodedFile\n",
    "output = io.BytesIO()\n",
    "encoded_file = codecs.EncodedFile(output, data_encoding='utf-8', file_encoding='utf-16')\n",
    "encoded_file.write(utf8)\n",
    "\n",
    "# 获取缓冲内容，编码为UTF-16\n",
    "utf16 = output.getvalue()\n",
    "print('Encoded to UTF-16:', to_hex(utf16,2))\n",
    "\n",
    "# 使用 UTF-16 数据设置另一个缓冲池，并且包装为另一个 EncodedFile\n",
    "buffer = io.BytesIO(utf16)\n",
    "encoded_file = codecs.EncodedFile(buffer, data_encoding='utf-8', file_encoding='utf-16')\n",
    "\n",
    "# 读取数据的 UTF-8 版本\n",
    "recoded = encoded_file.read()\n",
    "print('Back to UTF-8    :', to_hex(recoded, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROT_13: nopqrstuvwxyzabcdefghijklm\n"
     ]
    }
   ],
   "source": [
    "buffer = io.StringIO()\n",
    "stream = codecs.getwriter('rot_13')(buffer)  # rot_13解码器，旋转13个字符\n",
    "\n",
    "text = 'abcdefghijklmnopqrstuvwxyz'\n",
    "stream.write(text)\n",
    "stream.flush()\n",
    "\n",
    "print('ROT_13:', buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original len: 1350\n",
      "Compress len: 48\n",
      "First line: b'abcdefghijklmnopqrstuvwxyz\\n'\n",
      "Uncompress len: 1350\n",
      "Same ? : True\n"
     ]
    }
   ],
   "source": [
    "buffer = io.BytesIO()\n",
    "stream = codecs.getwriter('zlib')(buffer)\n",
    "text = b'abcdefghijklmnopqrstuvwxyz\\n' * 50\n",
    "\n",
    "stream.write(text)\n",
    "stream.flush()\n",
    "\n",
    "print('Original len:', len(text))\n",
    "compress_data = buffer.getvalue()\n",
    "print('Compress len:', len(compress_data))\n",
    "\n",
    "buffer = io.BytesIO(compress_data)\n",
    "stream = codecs.getreader('zlib')(buffer)\n",
    "\n",
    "first_line = stream.readline()\n",
    "print('First line:', first_line)\n",
    "uncompress_data = first_line + stream.read()\n",
    "print('Uncompress len:', len(uncompress_data))\n",
    "print('Same ? :', uncompress_data == text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text len: 27\n",
      "Repeat: 50\n",
      "Expect len: 1350\n",
      "\n",
      "Encoding:\n",
      ".................................................\n",
      "Encoded: 99 bytes\n",
      "Total encoded len: 99\n",
      "\n",
      "Decoding:\n",
      "........................................................................................\n",
      "Decoded: 1350 bytes\n",
      "Decoding:\n",
      "..........\n",
      "Total decoded len: 1350\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "text = b'abcdefghijklmnopqrstuvwxyz\\n' \n",
    "repeat = 50\n",
    "\n",
    "print('Text len:', len(text))\n",
    "print('Repeat:', repeat)\n",
    "print('Expect len:', len(text) * repeat)\n",
    "\n",
    "encoder = codecs.getincrementalencoder('bz2')()\n",
    "encoded = []\n",
    "print()\n",
    "print('Encoding:')\n",
    "last = repeat -1\n",
    "for i in range(repeat):\n",
    "    en_c = encoder.encode(text, final=(i==last))\n",
    "    if en_c:\n",
    "        print('\\nEncoded: {} bytes'.format(len(en_c)))\n",
    "        encoded.append(en_c)\n",
    "    else:\n",
    "        sys.stdout.write('.')\n",
    "        \n",
    "allencoded = b''.join(encoded)\n",
    "print('Total encoded len:', len(allencoded))\n",
    "\n",
    "decoder = codecs.getincrementaldecoder('bz2')()\n",
    "decoded = []\n",
    "print()\n",
    "print('Decoding:')\n",
    "for i,b in enumerate(allencoded):\n",
    "    final = (i+1) == len(text)\n",
    "    c = decoder.decode(bytes([b]), final)\n",
    "    if c:\n",
    "        print('\\nDecoded: {} bytes'.format(len(c)))\n",
    "        print('Decoding:')\n",
    "        decoded.append(c)\n",
    "    else:\n",
    "        sys.stdout.write('.')\n",
    "        \n",
    "restored = b''.join(decoded)\n",
    "print()\n",
    "print('Total decoded len:', len(restored))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可能会在数据流处理时大幅改变数据流的长度。对于大数据集，这些操作最好是渐进式的，一次只处理小量数据块，IncrementalEncoder 和 IncrementalDecoder则设计用于这个目的。每次传递给编码器或者解码器的时候，其内部状态会更新。当状态一致的时候（由编解码器定义），数据返回并且状态重置。在那之前，调用 encode() 或者 decode() 将不会返回任何数据。当传入最后一批数据时，参数 final 应该设置为 True，因此编解码器直到清除所有剩余的缓冲数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 网络通信"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-a2c3f33c37c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# 发送数据，未进行编码，会报错\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'français'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mlen_sent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen_sent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "import socketserver\n",
    "import socket\n",
    "import threading\n",
    "\n",
    "class Echo(socketserver.BaseRequestHandler):\n",
    "    def handle(self):\n",
    "        data = self.request.recv(1024)\n",
    "        self.request.send(data)\n",
    "        return\n",
    "\n",
    "address = ('localhost', 0)\n",
    "server = socketserver.TCPServer(address, Echo)\n",
    "ip, port = server.server_address\n",
    "t = threading.Thread(target=server.serve_forever)\n",
    "t.setDaemon(True)\n",
    "t.start()\n",
    "\n",
    "s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "s.connect((ip, port))\n",
    "\n",
    "# 发送数据，未进行编码，会报错\n",
    "text = 'français'\n",
    "len_sent = s.send(text)\n",
    "\n",
    "response = s.recv(len_sent)\n",
    "print(repr(response))\n",
    "s.close()\n",
    "server.socket.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending: 'français'\n",
      "Writing: b'fran\\xc3\\xa7ais'\n",
      "Reading:\n",
      "b'fran\\xc3\\xa7ais'\n",
      "Reading:\n",
      "b''\n",
      "Recived: 'français'\n"
     ]
    }
   ],
   "source": [
    "class PassThrough:\n",
    "    def __init__(self, other):\n",
    "        self.other = other\n",
    "        \n",
    "    def write(self, data):\n",
    "        print('Writing:', repr(data))\n",
    "        return self.other.write(data)\n",
    "    \n",
    "    def read(self, size=-1):\n",
    "        print('Reading:')\n",
    "        data = self.other.read(size)\n",
    "        print(repr(data))\n",
    "        return data\n",
    "    \n",
    "    def flush(self):\n",
    "        return self.other.flush()\n",
    "    \n",
    "    def close(self):\n",
    "        return self.other.close()\n",
    "    \n",
    "address = ('localhost', 0)\n",
    "server = socketserver.TCPServer(address, Echo)\n",
    "ip, port = server.server_address\n",
    "t = threading.Thread(target=server.serve_forever)\n",
    "t.setDaemon(True)\n",
    "t.start()\n",
    "\n",
    "s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "s.connect((ip, port))\n",
    "\n",
    "# 使用读取器和写入器包装套接字\n",
    "read_file = s.makefile('rb')\n",
    "incoming = codecs.getreader('utf-8')(PassThrough(read_file))\n",
    "write_file = s.makefile('wb')\n",
    "outgoing = codecs.getwriter('utf-8')(PassThrough(write_file))\n",
    "\n",
    "text = 'français'\n",
    "print('Sending:', repr(text))\n",
    "outgoing.write(text)\n",
    "outgoing.flush()\n",
    "\n",
    "response = incoming.read()\n",
    "print('Recived:',repr(response))\n",
    "s.close()\n",
    "server.socket.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定义编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def invertcaps(text):\n",
    "    \"\"\"Return new string with the case of all letters switched.\n",
    "    \"\"\"\n",
    "    return ''.join(\n",
    "        c.upper() if c in string.ascii_lowercase\n",
    "        else c.lower() if c in string.ascii_uppercase\n",
    "        else c\n",
    "        for c in text\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcDEF\n",
      "ABCdef\n"
     ]
    }
   ],
   "source": [
    "print(invertcaps('ABCdef'))\n",
    "print(invertcaps('abcDEF'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一步是去了解编码转换的性质。尽管它很容易理解，但是实现并不高效，特别是对于大文本字符串。  \n",
    "codecs 包含一些用于创建基于字符映射的编解码器的辅助函数。字符映射编码由两个字典组成。编码字典将输入字符串中的字符值转换为输出中的字节值，解码字典则以另一种方式运行。首先创建解码映射，然后使用 make_encoding_map() 将其转换为编码映射。C 函数 charmap_encode() 和 charmap_decode() 使用这种映射关系高效地转换他们的输入数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b'ABCdef', 6)\n",
      "('ABCdef', 6)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "import string\n",
    "\n",
    "decoding_map = codecs.make_identity_dict(range(256))\n",
    "\n",
    "pairs = list(zip([ord(c) for c in string.ascii_lowercase], [ord(c) for c in string.ascii_uppercase]))\n",
    "decoding_map.update({upper:lower for (lower, upper) in pairs})\n",
    "decoding_map.update({lower:upper for (lower, upper) in pairs})\n",
    "             \n",
    "encoding_map = codecs.make_encoding_map(decoding_map)\n",
    "\n",
    "print(codecs.charmap_encode('abcDEF', 'strict', encoding_map))\n",
    "print(codecs.charmap_decode(b'abcDEF', 'strict', decoding_map))\n",
    "print(decoding_map == encoding_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ignore :(b'PI: ', 5)\n",
      "replace:(b'PI: ?', 5)\n",
      "strict :'charmap' codec can't encode character '\\u03c0' in position 4: character maps to <undefined>\n"
     ]
    }
   ],
   "source": [
    "text = 'pi: \\u03c0'  # π 的 Unicode 码点没有在这个编码图中\n",
    "\n",
    "for error in ['ignore', 'replace', 'strict']:\n",
    "    try:\n",
    "        encoded = codecs.charmap_encode(text, error, encoding_map)\n",
    "    except UnicodeEncodeError as err:\n",
    "        encoded = str(err)\n",
    "        \n",
    "    print(f'{error:7}:{encoded}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<codecs.CodecInfo object for encoding utf-8 at 0x1039ab2e8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codecs.lookup('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "class InvertCapsCodec(codecs.Codec):\n",
    "    def encode(self, input, errors='strict'):\n",
    "        return codecs.charmap_encode(input, errors, encoding_map)\n",
    "    def decode(self, input, errors='strict'):\n",
    "        return codecs.charmap_decode(input, errors, decoding_map)\n",
    "    \n",
    "class InvertCapsIncrementalEncoder(codecs.IncrementalEncoder):\n",
    "    def encode(self, input, final=False):\n",
    "        data, nbytes = codecs.charmap_encode(input, self.errors, encoding_map)\n",
    "        return data\n",
    "    \n",
    "class InvertCapsIncrementalDecoder(codecs.IncrementalDecoder):\n",
    "    def decode(self, input, final=False):\n",
    "        data, nbytes = codecs.charmap_decode(input, self.errors, decoding_map)\n",
    "        return data\n",
    "    \n",
    "class InvertCapsStreamReader(InvertCapsCodec, codecs.StreamReader):\n",
    "    pass\n",
    "class InvertCapsStreamWriter(InvertCapsCodec, codecs.StreamWriter):\n",
    "    pass\n",
    "\n",
    "def find_invertcaps(encoding):\n",
    "    if encoding == 'invertcaps':\n",
    "        return codecs.CodecInfo(name='invertcaps', encode=InvertCapsCodec().encode, decode=InvertCapsCodec().decode,\n",
    "                               incrementalencoder=InvertCapsIncrementalEncoder, incrementaldecoder=InvertCapsIncrementalDecoder,\n",
    "                                streamreader=InvertCapsStreamReader, streamwriter=InvertCapsStreamWriter,)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded abcDEF to b'ABCdef', consuming 6 chars\n",
      "StreamWriter for io buffer : writing abcDEF\n",
      "buffer contents: b'ABCdef'\n",
      "IncrementalDecoder converted b'ABCdef' to 'abcDEF'\n"
     ]
    }
   ],
   "source": [
    "codecs.register(find_invertcaps)\n",
    "\n",
    "encoder = codecs.getencoder('invertcaps')\n",
    "text = 'abcDEF'\n",
    "encoded_text, consumed = encoder(text)\n",
    "print(f\"Encoded {text} to {encoded_text}, consuming {consumed} chars\")\n",
    "\n",
    "import io\n",
    "buffer = io.BytesIO()\n",
    "writer = codecs.getwriter('invertcaps')(buffer)\n",
    "print('StreamWriter for io buffer : writing abcDEF')\n",
    "writer.write('abcDEF')\n",
    "print('buffer contents:', buffer.getvalue())\n",
    "\n",
    "decoder_factory = codecs.getincrementaldecoder('invertcaps')\n",
    "decoder = decoder_factory()\n",
    "decoded_text_parts = []\n",
    "for c in encoded_text:\n",
    "    decoded_text_parts.append(decoder.decode(bytes([c]), final=False))\n",
    "decoded_text_parts.append(decoder.decode(b'', final=True))\n",
    "decoded_text = ''.join(decoded_text_parts)\n",
    "print(f'IncrementalDecoder converted {encoded_text!r} to {decoded_text!r}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
